### GARPN
Train garpn using config garpn_r50_fpn_1x.py  
Performance on val2017  
AR100: 0.5860  
AR300: 0.6484  
AR1000: 0.6816

### HTC
Train htc using config htc_r50_fpn_1x.py (without semantic branch)  
Performance on val2017  
BBox AP: 0.415  
Mask AP: 0.366  
Test with proposals generated by garpn (the htc is not finetuned)  
Performance on val2017  
BBox AP: 0.403  
Mask AP: 0.356 

### HTC finetuned with GARPN
Finetune htc with proposals generated by garpn for 3 epochs, using config htc_r50_fpn_finetune_with_garpn.py  
Test with original rpn proposals (lower recall than garpn)  
Performance on val2017  
BBox AP: 0.412  
Mask AP: 0.364 
Test with proposals generated by garpn  
Performance on val2017  
BBox AP: 0.415  
Mask AP: 0.366  

### HTC with GARPN
Train htc with garpn end to end  
Using config htc_r50_fpn_garpn_1x_v1.py (Less samples each stage)  
Performance on val2017  
BBox AP: 0.412  
Mask AP: 0.364

Using config htc_r50_fpn_garpn_1x_v2.py (Higher iou_thr each stage)  
Performance on val2017  
BBox AP: 0.415  
Mask AP: 0.367

Using config htc_r50_fpn_garpn_1x_v3.py (Modify each stage's bbox target mean and std)  
Performance on val2017  
BBox AP: 0.413  
Mask AP: 0.363